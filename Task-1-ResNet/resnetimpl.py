# -*- coding: utf-8 -*-
"""resnetimpl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hGEER6tWbZc0MK4yIDtuhIkOA8E6k0Op
"""

import numpy as np
import matplotlib.pyplot as plt

import torch
import torchvision
import torchvision.transforms as transforms

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models
import pdb

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

transform = transforms.Compose(
            [
                torchvision.transforms.Resize((224,224)),
                torchvision.transforms.ToTensor(),
                torchvision.transforms.Normalize(mean=[0.49139968, 0.48215841,  0.44653091],
                                     std=[0.24703223, 0.24348513, 0.26158784])
            ]
        )

batch_size = 256
train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle = True, num_workers=2)

valid_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle = True,num_workers=2)

classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')

import numpy as np
import matplotlib.pyplot as plt
def imshow(img):
  img = img / 2 + 0.5
  npimg = img.numpy()
  plt.imshow(np.transpose(npimg, (1, 2, 0)))
  plt.show()


dataiter = iter(train_loader)
images, labels = dataiter.__next__()

imshow(torchvision.utils.make_grid(images))
print(labels)
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))

# for images, labels in train_loader:
#     imshow(torchvision.utils.make_grid(images))
#     print(labels)
#     break

# import torch.nn as nn
# import torch.nn.functional as F

# class Net(nn.Module):
#   def __init__(self):
#     super().__init__()
#     self.conv1 = nn.Conv2d(3, 16, 3, 1, padding =1)
#     self.conv2 = nn.Conv2d(16, 32, 3, 1, padding =1)
#     self.conv3 = nn.Conv2d(32, 64, 3, 1, padding =1)
#     self.fc1 = nn.Linear(4*4*64,500)
#     self.droput1 = nn.Dropout(0.2)
#     self.fc2 = nn.Linear(500,10)
#   def forward(self,x):
#     x = F.relu(self.conv1(x))
#     x = F.max_pool2d(x, 2, 2)
#     x = F.relu(self.conv2(x))
#     x = F.max_pool2d(x, 2, 2)
#     x = F.relu(self.conv3(x))
#     x = F.max_pool2d(x, 2, 2)
#     x = x.view(-1 , 4*4*64)
#     x = F.relu(self.fc1(x))
#     x = self.droput1(x)
#     x = self.fc2(x)
#     #x = F.relu(self.fc2(x))
#     return x

class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super().__init__()
        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,
                     padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,
                     padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out

def _make_layer(block, inplanes,planes, blocks, stride=1):
    downsample = None  
    if stride != 1 or inplanes != planes:
        downsample = nn.Sequential(            
            nn.Conv2d(inplanes, planes, 1, stride, bias=False),
            nn.BatchNorm2d(planes),
        )
    layers = []
    layers.append(block(inplanes, planes, stride, downsample))
    inplanes = planes
    for _ in range(1, blocks):
        layers.append(block(inplanes, planes))
    return nn.Sequential(*layers)

class ResNet(nn.Module):

    def __init__(self, block, layers, num_classes=10):
        super().__init__()
        
        self.inplanes = 64

        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,
                               bias=False)
        self.bn1 = nn.BatchNorm2d(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
        
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 , num_classes)


    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None  
   
        if stride != 1 or self.inplanes != planes:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes, 1, stride, bias=False),
                nn.BatchNorm2d(planes),
              )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        
        self.inplanes = planes
        
        for _ in range(1, blocks):
            layers.append(block(self.inplanes, planes))

        return nn.Sequential(*layers)
    
    
    def forward(self, x):
        x = self.conv1(x)           # 224x224
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)         # 112x112

        x = self.layer1(x)          # 56x56
        x = self.layer2(x)          # 28x28
        x = self.layer3(x)          # 14x14
        x = self.layer4(x)          # 7x7

        x = self.avgpool(x)         # 1x1
        x = torch.flatten(x, 1)      
        x = self.fc(x)

        return x

def resnet34():
    layers=[3, 4, 6, 3]
    model = ResNet(BasicBlock, layers)
    return model

model=resnet34()

print(device)
net = model.cuda()

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
Optimizer = optim.SGD(net.parameters(),lr=0.01,momentum =0.9)

epochs = 4
running_loss_history =[]
running_corrects_history = []
val_running_loss_history = []
val_running_corrects_history = []

for e in range(epochs):
  running_loss = 0.0
  running_corrects = 0.0
  val_running_loss = 0.0
  val_running_corrects = 0.0

  for inputs,labels in train_loader:
    inputs=inputs.to(device)
    labels = labels.to(device)
    outputs = net(inputs)
    loss = criterion(outputs,labels)

    Optimizer.zero_grad()
    loss.backward()
    Optimizer.step()

    _, preds = torch.max(outputs, 1)
    running_loss += loss.item()
    running_corrects += torch.sum(preds == labels.data)

  with torch.no_grad():
    for val_inputs,val_labels in valid_loader:
       val_inputs = val_inputs.to(device)
       val_labels = val_labels.to(device)
       val_outputs = net(val_inputs)
       val_loss = criterion(val_outputs,val_labels)

       _, val_preds = torch.max(val_outputs, 1)
       val_running_loss += val_loss.item()
       val_running_corrects += torch.sum(val_preds == val_labels.data)

  epoch_loss = running_loss/(len(train_loader)*batch_size)
  epoch_acc = running_corrects.float()/(len(train_loader)*batch_size)
  running_loss_history.append(epoch_loss)
  running_corrects_history.append(epoch_acc.cpu().numpy())

  val_epoch_loss = val_running_loss/(len(valid_loader)*batch_size)
  val_epoch_acc = val_running_corrects.float()/(len(valid_loader)*batch_size)
  val_running_loss_history.append(val_epoch_loss)
  val_running_corrects_history.append(val_epoch_acc.cpu().numpy())

  print('epoch :', (e+1))
  print('training loss: {:.4f}, acc {:.4f} '.format(epoch_loss, epoch_acc.item()))
  print('validation loss: {:.4f}, validation acc {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))

plt.style.use('ggplot')
plt.plot(running_loss_history, label = 'training loss')
plt.plot(val_running_loss_history, label = 'validation loss')
plt.legend()

plt.style.use('ggplot')
plt.plot(running_corrects_history, label = 'training accuracy')
plt.plot(val_running_corrects_history, label = 'validation accuracy')
plt.legend()