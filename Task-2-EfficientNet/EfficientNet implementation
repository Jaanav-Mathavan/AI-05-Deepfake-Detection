import torch
import torch.nn as nn
from math import ceil
import torchvision
import torchvision.transforms as transforms

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)

base_model = [
    [1, 16, 1, 1, 3],
    [6, 24, 2, 2, 3],
    [6, 40, 2, 2, 5],
    [6, 80, 3, 2, 3],
    [6, 112, 3, 1, 5],
    [6, 192, 4, 2, 5],
    [6, 320, 1, 1, 3],
]

phi_values = {
    "b0": (0, 224, 0.2),  # alpha, beta, gamma, depth = alpha ** phi
    "b1": (0.5, 240, 0.2),
    "b2": (1, 260, 0.3),
    "b3": (2, 300, 0.3),
    "b4": (3, 380, 0.4),
    "b5": (4, 456, 0.4),
    "b6": (5, 528, 0.5),
    "b7": (6, 600, 0.5),
}


class CNNBlock(nn.Module):
    def __init__(
        self, in_channels, out_channels, kernel_size, stride, padding, groups=1
    ):
        super(CNNBlock, self).__init__()
        self.cnn = nn.Conv2d(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding,
            groups=groups,
            bias=False,
        )
        self.bn = nn.BatchNorm2d(out_channels)
        self.silu = nn.SiLU()  

    def forward(self, x):
        return self.silu(self.bn(self.cnn(x)))


class SqueezeExcitation(nn.Module):
    def __init__(self, in_channels, reduced_dim):
        super(SqueezeExcitation, self).__init__()
        self.se = nn.Sequential(
            nn.AdaptiveAvgPool2d(1), 
            nn.Conv2d(in_channels, reduced_dim, 1),
            nn.SiLU(),
            nn.Conv2d(reduced_dim, in_channels, 1),
            nn.Sigmoid(),
        )

    def forward(self, x):
        return x * self.se(x)


class InvertedResidualBlock(nn.Module):
    def __init__(
        self,
        in_channels,
        out_channels,
        kernel_size,
        stride,
        padding,
        expand_ratio,
        reduction=4,  
        survival_prob=0.8,  
    ):
        super(InvertedResidualBlock, self).__init__()
        self.survival_prob = 0.8
        self.use_residual = in_channels == out_channels and stride == 1
        hidden_dim = in_channels * expand_ratio
        self.expand = in_channels != hidden_dim
        reduced_dim = int(in_channels / reduction)

        if self.expand:
            self.expand_conv = CNNBlock(
                in_channels,
                hidden_dim,
                kernel_size=3,
                stride=1,
                padding=1,
            )

        self.conv = nn.Sequential(
            CNNBlock(
                hidden_dim,
                hidden_dim,
                kernel_size,
                stride,
                padding,
                groups=hidden_dim,
            ),
            SqueezeExcitation(hidden_dim, reduced_dim),
            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels),
        )

    def stochastic_depth(self, x):
        '''randomly drop out some blocks to avoid overfitting'''
        if not self.training:
            return x

        binary_tensor = (
            torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob
        )
        return torch.div(x, self.survival_prob) * binary_tensor

    def forward(self, inputs):
        x = self.expand_conv(inputs) if self.expand else inputs

        if self.use_residual:
            return self.stochastic_depth(self.conv(x)) + inputs
        else:
            return self.conv(x)


class EfficientNet(nn.Module):
    def __init__(self, version, num_classes):
        super(EfficientNet, self).__init__()
        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)
        last_channels = ceil(1280 * width_factor)
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.features = self.create_features(width_factor, depth_factor, last_channels)
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(last_channels, num_classes),
        )

    def calculate_factors(self, version, alpha=1.2, beta=1.1):
        phi, res, drop_rate = phi_values[version]
        depth_factor = alpha**phi
        width_factor = beta**phi
        return width_factor, depth_factor, drop_rate

    def create_features(self, width_factor, depth_factor, last_channels):
        channels = int(32 * width_factor)
        features = [CNNBlock(3, channels, 3, stride=2, padding=1)]
        in_channels = channels

        for expand_ratio, channels, repeats, stride, kernel_size in base_model:
            out_channels = 4 * ceil(int(channels * width_factor) / 4)
            layers_repeats = ceil(repeats * depth_factor)

            for layer in range(layers_repeats):
                features.append(
                    InvertedResidualBlock(
                        in_channels,
                        out_channels,
                        expand_ratio=expand_ratio,
                        stride=stride if layer == 0 else 1,
                        kernel_size=kernel_size,
                        padding=kernel_size // 2,
                    )
                )
                in_channels = out_channels

        features.append(
            CNNBlock(in_channels, last_channels, kernel_size=1, stride=1, padding=0)
        )

        return nn.Sequential(*features)

    def forward(self, x):
        x = self.pool(self.features(x))
        return self.classifier(x.view(x.shape[0], -1))


# def test():
#     device = "cuda" if torch.cuda.is_available() else "cpu"
#     version = "b0"
#     phi, res, drop_rate = phi_values[version]
#     num_examples, num_classes = 4, 10
#     x = torch.randn((num_examples, 3, res, res)).to(device)
#     model = EfficientNet(
#         version=version,
#         num_classes=num_classes,
#     ).to(device)

#     print(model(x).shape)  # (num_examples, num_classes)



# if __name__ == "__main__":
#     test()

def test():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    version = "b0"
    phi, res, drop_rate = phi_values[version]
    num_classes = 10


    model = EfficientNet(version=version, num_classes=num_classes).to(device)

    model.eval()

    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in testloader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)

            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f"Accuracy on the CIFAR-10 test set: {100 * correct / total:.2f}%")

def train():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    version = "b0"
    phi, res, drop_rate = phi_values[version]
    num_classes = 10

    model = EfficientNet(version=version, num_classes=num_classes).to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=125, shuffle=True, num_workers=2)

    num_epochs = 20

    for epoch in range(num_epochs):
        running_loss = 0.0

        for i, (inputs, labels) in enumerate(trainloader, 0):
            inputs = inputs.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            if i % 2000 == 1999:
                print(f"[Epoch {epoch+1}, Batch {i+1}] Loss: {running_loss / 2000:.3f}")
                running_loss = 0.0

    print("Training finished.")
    model.eval()

    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in testloader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)

            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f"Accuracy on the CIFAR-10 test set: {100 * correct / total:.2f}%")

if __name__ == "__main__":
    train()
    # test()

LEARNINGS:

In EfficientNet-B0, Block 2 consists of multiple repeated Inverted Residual Blocks. Let's go through the flow of an image through each block in Block 2:

1. Block 2, Layer 1:
   - The input feature map from Block 1 is passed through an Inverted Residual Block.
   - Inside the Inverted Residual Block, the feature map is first expanded using a 1x1 convolution to increase the number of channels.
   - Next, a depth-wise convolution is applied with a kernel size of 3x3 to capture spatial features.
   - The resulting feature map is then projected back to the original number of channels using a 1x1 convolution.
   - A squeeze-and-excitation module may be applied to capture channel-wise dependencies and recalibrate the feature map.
   - The output of this block is the processed feature map.

2. Block 2, Layer 2:
   - The processed feature map from the previous layer is passed through another Inverted Residual Block, following the same operations as described above.
   - The input and output dimensions remain the same, but the learned features and channel-wise recalibration may differ.

3. Block 2, Layer 3:
   - Similar to the previous layers, the processed feature map is passed through another Inverted Residual Block.
   - Again, the input and output dimensions remain the same, but the specific learned features and recalibration may vary.

4. Block 2, Layer 4:
   - This layer follows the same pattern as the previous layers.
   - The processed feature map is passed through an Inverted Residual Block with the same input and output dimensions.

The above steps represent the flow through the individual layers within Block 2. These layers are repeated based on the specific configuration of EfficientNet-B0. The number of layers and their characteristics depend on the architecture and scaling factors.

It's important to note that the overall flow through Block 2 involves passing the feature map from one layer to the next, allowing the network to capture increasingly complex and abstract representations of the input image.

REFERENCES:
https://towardsdatascience.com/squeeze-and-excitation-networks-9ef5e71eacd7
https://www.coursera.org/learn/convolutional-neural-networks/lecture/9BqTk/mobilenet-architecture
https://arxiv.org/pdf/1905.11946.pdf
https://towardsdatascience.com/complete-architectural-details-of-all-efficientnet-models-5fd5b736142
