# -*- coding: utf-8 -*-
"""effnetimpl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/179kjYUfq6KDtpnJB8W_5UJmUeRh04DEM
"""

import numpy as np
import matplotlib.pyplot as plt

import torch
import torchvision
import torchvision.transforms as transforms

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models
import pdb

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

transform = transforms.Compose(
            [
                torchvision.transforms.Resize((224,224)),
                torchvision.transforms.ToTensor(),
                torchvision.transforms.Normalize(mean=[0.49139968, 0.48215841,  0.44653091],
                                     std=[0.24703223, 0.24348513, 0.26158784])
            ]
        )

batch_size = 256
train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle = True, num_workers=2)

valid_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle = True,num_workers=2)

classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')

import numpy as np
import matplotlib.pyplot as plt
def imshow(img):
  img = img / 2 + 0.5
  npimg = img.numpy()
  plt.imshow(np.transpose(npimg, (1, 2, 0)))
  plt.show()


dataiter = iter(train_loader)
images, labels = dataiter.__next__()

imshow(torchvision.utils.make_grid(images))
print(labels)
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))

# for images, labels in train_loader:
#     imshow(torchvision.utils.make_grid(images))
#     print(labels)
#     break

# import torch
# from efficientnet_v2 import EfficientNetV2
from torchvision.models import efficientnet_b0,EfficientNet_B0_Weights

!pip install efficientnet_pytorch

print(device)

import torch.nn as nn

from efficientnet_pytorch import EfficientNet

# Load the pre-trained EfficientNet model
model = EfficientNet.from_pretrained('efficientnet-b0')
#model = efficientnet_b0(pretrained = True)
for param in model.parameters():
    param.requires_grad = False
    # Replace the last fully-connected layer
    # Parameters of newly constructed modules have requires_grad=True by default
# Get the number of input features for the last layer
in_features = model._fc.in_features

# Replace the last layer with a new layer with 2 output units
model._fc = nn.Linear(in_features, 10)
#model._fc = nn.Linear(final_layer _, 10) # assuming that the fc7 layer has 512 neurons, otherwise change it 
model.cuda()

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
Optimizer = optim.SGD(model.parameters(),lr=0.01,momentum =0.9)

epochs = 4
running_loss_history =[]
running_corrects_history = []
val_running_loss_history = []
val_running_corrects_history = []

for e in range(epochs):
  running_loss = 0.0
  running_corrects = 0.0
  val_running_loss = 0.0
  val_running_corrects = 0.0

  for inputs,labels in train_loader:
    inputs=inputs.to(device)
    labels = labels.to(device)
    outputs = model(inputs)
    loss = criterion(outputs,labels)

    Optimizer.zero_grad()
    loss.backward()
    Optimizer.step()

    _, preds = torch.max(outputs, 1)
    running_loss += loss.item()
    running_corrects += torch.sum(preds == labels.data)

  with torch.no_grad():
    for val_inputs,val_labels in valid_loader:
       val_inputs = val_inputs.to(device)
       val_labels = val_labels.to(device)
       val_outputs = model(val_inputs)
       val_loss = criterion(val_outputs,val_labels)

       _, val_preds = torch.max(val_outputs, 1)
       val_running_loss += val_loss.item()
       val_running_corrects += torch.sum(val_preds == val_labels.data)

  epoch_loss = running_loss/(len(train_loader)*batch_size)
  epoch_acc = running_corrects.float()/(len(train_loader)*batch_size)
  running_loss_history.append(epoch_loss)
  running_corrects_history.append(epoch_acc.cpu().numpy())

  val_epoch_loss = val_running_loss/(len(valid_loader)*batch_size)
  val_epoch_acc = val_running_corrects.float()/(len(valid_loader)*batch_size)
  val_running_loss_history.append(val_epoch_loss)
  val_running_corrects_history.append(val_epoch_acc.cpu().numpy())

  print('epoch :', (e+1))
  print('training loss: {:.4f}, acc {:.4f} '.format(epoch_loss, epoch_acc.item()))
  print('validation loss: {:.4f}, validation acc {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))

plt.style.use('ggplot')
plt.plot(running_loss_history, label = 'training loss')
plt.plot(val_running_loss_history, label = 'validation loss')
plt.legend()

plt.style.use('ggplot')
plt.plot(running_corrects_history, label = 'training accuracy')
plt.plot(val_running_corrects_history, label = 'validation accuracy')
plt.legend()